{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<small><i>This tutorial was put together by [Alexander Fridman](http://www.rocketscience.ai) and [Volha Hedranovich](http://www.rocketscience.ai) for the Lecture Course. Source and license info is on [GitHub](https://github.com/volhahedranovich/jupyter_lectures).</i></small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 5. Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture outline\n",
    "\n",
    "1. [Key Python packages and projects for NLP](NLP_Tasks.ipynb#Key-Python-packages-&-projects-for-NLP)\n",
    "  * <span style=\"color:#757575\">scikit-learn</span>\n",
    "  * <span style=\"color:#757575\">NLTK</span>\n",
    "  * <span style=\"color:#757575\">spaCy</span>\n",
    "  * <span style=\"color:#757575\">WordNet</span>\n",
    "<p></p>\n",
    "2. [NLP Basic Tasks](NLP_Tasks.ipynb#NLP-Basic-Tasks)\n",
    "  * <span style=\"color:#757575\">POS Tagging</span>\n",
    "  * <span style=\"color:#757575\">WSD</span>\n",
    "  * <span style=\"color:#757575\">NER</span>\n",
    "  * <span style=\"color:#757575\">Language Identification</span>\n",
    "  * <span style=\"color:#757575\">Text Summarisation</span>\n",
    "  * <span style=\"color:#757575\">Sentiment Analysis</span>\n",
    "  * <span style=\"color:#757575\">Semantic Text Similarity</span>\n",
    "  * <span style=\"color:#757575\">Topic Modeling</span>\n",
    "<p></p>\n",
    "3. [Key Text Preprocessing Techniques](NLP_Tasks.ipynb#Key-text-preprocessing-techniques)\n",
    "  * <span style=\"color:#757575\">Text Cleaning (RegExp)</span>\n",
    "  * <span style=\"color:#757575\">Tokenizing</span>\n",
    "  * <span style=\"color:#757575\">Stopwords removal</span>\n",
    "  * <span style=\"color:#757575\">Spelling Correction</span>\n",
    "  * <span style=\"color:#757575\">Synonyms Replacement</span>\n",
    "  * <span style=\"color:#757575\">Negation Replacement</span>\n",
    "  * <span style=\"color:#757575\">Stemming and Lemmatization</span>\n",
    "  * <span style=\"color:#757575\">N-grams adding</span>\n",
    "<p></p>\n",
    "4. [Key Text Vectorization Techniques](NLP_Tasks.ipynb#Key-text-vectorization-techniques)\n",
    "  * <span style=\"color:#757575\">BOW</span>\n",
    "  * <span style=\"color:#757575\">CountVec</span>\n",
    "  * <span style=\"color:#757575\">TF-IDF</span>\n",
    "  * <span style=\"color:#757575\">Hashing trick</span>\n",
    "  * <span style=\"color:#757575\">...2vec</span>\n",
    "<p></p>\n",
    "5. [Case study. Text classification](NLP_Case_Study.ipynb)\n",
    "  * Text reprocessing techniques\n",
    "    * <span style=\"color:#757575\">Replacing words matching regular expressions</span>\n",
    "    * <span style=\"color:#757575\">Basic cleaning with regexps</span>\n",
    "    * <span style=\"color:#757575\">Tokenization</span>\n",
    "    * <span style=\"color:#757575\">Removing repeated characters</span>\n",
    "    * <span style=\"color:#757575\">Stopwords removal</span>\n",
    "    * <span style=\"color:#757575\">Adding n-grams</span>\n",
    "    * <span style=\"color:#757575\">Spelling correction</span>\n",
    "    * <span style=\"color:#757575\">Lemmatization</span>\n",
    "    * <span style=\"color:#757575\">Stemming</span>\n",
    "    * <span style=\"color:#757575\">Adding synonyms</span>\n",
    "  * Vectorization\n",
    "    * <span style=\"color:#757575\">Dummy CountVectoriser</span>\n",
    "    * <span style=\"color:#757575\">TfIdf</span>\n",
    "    * <span style=\"color:#757575\">Hashing trick</span>\n",
    "  * Classification with any algo\n",
    "<p></p><p></p>\n",
    "6. [Sequence Data Approach. Using RNNs for text classification](NLP_NN_Text_Classifictioin[optional].ipynb)\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homework\n",
    "\n",
    "Take part in the challenge **Predict the Happiness**.\n",
    "\n",
    "Problem Statement, Data and Submission form see [here](https://www.hackerearth.com/problem/machine-learning/predict-the-happiness/).\n",
    "\n",
    "Share your best scores in the Slack channel <span style=\"color:#33742c\">`#nlp`</span>, in the thread (available on the tag <span style=\"color:#33742c\">*#nlp-homework1*</span>).\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of abbreviations\n",
    "\n",
    "NLP &#8212; Natural Language Processing (NLP)\n",
    "\n",
    "NLTK &#8212; Natural Language Toolkit\n",
    "\n",
    "POS &#8212; Part-Of-Speech\n",
    "\n",
    "NER &#8212; Named Entity Recognition\n",
    "\n",
    "RegExp &#8212; Regular Expressions\n",
    "\n",
    "BOW &#8212; Bag of Words\n",
    "\n",
    "TfIDF &#8212; Term Frequency – Inverse Document Frequency (tf–idf or TFIDF)\n",
    "\n",
    "WSD &#8212; Word-Sense Disambiguation\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "1. Jacob Perkins. [Python 3 Text Processing with NLTK 3 Cookbook](https://www.packtpub.com/application-development/python-3-text-processing-nltk-3-cookbook)\n",
    "2. The Stanford Natural Language Processing Group. [Software](https://nlp.stanford.edu/software/)\n",
    "3. Platform for building Python programs to work with human language data [NLTK](http://www.nltk.org/)\n",
    "4. Python library for NLP [spaCy](https://spacy.io/usage/)\n",
    "5. Analytics Vidhya. NSS. [The Essential NLP Guide for data scientists (with codes for top 10 common NLP tasks)](https://www.analyticsvidhya.com/blog/2017/10/essential-nlp-guide-data-scientists-top-10-nlp-tasks/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_sm\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import pandas as pd\n",
    "\n",
    "from collections import Counter\n",
    "from gensim.summarization import summarize\n",
    "from IPython.display import display, HTML\n",
    "from langdetect import detect\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.classify.util import accuracy\n",
    "from pywsd.lesk import simple_lesk\n",
    "from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer\n",
    "from spacy import displacy\n",
    "from tabulate import tabulate\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
